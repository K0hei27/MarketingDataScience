{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h-IE-pEY-0Og"
   },
   "source": [
    "## Using Apriori Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fmarciaturner%2Ffiles%2F2018%2F01%2FWegmans-Produce-1.jpg\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequent Itemsets via Apriori Algorithm\n",
    "Apriori function to extract frequent itemsets for association rule mining\n",
    "We have a dataset of a mall with 7500 transactions of different customers buying different items from the store.\n",
    "We have to find correlations between the different items in the store. so that we can know if a customer is buying apple, banana and mango. what is the next item, The customer would be interested in buying from the store. \n",
    "\n",
    "## Overview\n",
    "Apriori is a popular algorithm for extracting frequent itemsets with applications in association rule learning. The apriori algorithm has been designed to operate on databases containing transactions, such as purchases by customers of a store. An itemset is considered as \"frequent\" if it meets a user-specified support threshold. For instance, if the support threshold is set to 0.5 (50%), a frequent itemset is defined as a set of items that occur together in at least 50% of all transactions in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RODwj2Ug-9lH"
   },
   "source": [
    "**Importing libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting squarify\n",
      "  Downloading https://files.pythonhosted.org/packages/0b/2b/2e77c35326efec19819cd1d729540d4d235e6c2a3f37658288a363a67da5/squarify-0.4.3-py3-none-any.whl\n",
      "Installing collected packages: squarify\n",
      "Successfully installed squarify-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install squarify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-output": true,
    "colab": {},
    "colab_type": "code",
    "id": "72zscNfA-sYt"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9b45e97519b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# for defining path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# for market basket analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/'"
     ]
    }
   ],
   "source": [
    "# for basic operations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# for visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import squarify\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# for defining path\n",
    "import os\n",
    "print(os.listdir('../input/'))\n",
    "\n",
    "# for market basket analysis\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lP0H9a4pAg-p"
   },
   "source": [
    "**Importing the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "colab_type": "code",
    "id": "OTEXbC-TAfVO",
    "outputId": "a55b4f7a-9995-46d0-b431-1978e4170f49"
   },
   "outputs": [],
   "source": [
    "# reading the dataset\n",
    "\n",
    "data = pd.read_csv('../input/Market_Basket_Optimisation.csv', header = None)\n",
    "\n",
    "# let's check the shape of the dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# checking the head of the data\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkng the tail of the data\n",
    "\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the random entries in the data\n",
    "\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "g3qz9RBeBfSY",
    "outputId": "56093766-a673-460d-ec1b-282c3e0b2547"
   },
   "outputs": [],
   "source": [
    "# let's describe the dataset\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628
    },
    "colab_type": "code",
    "id": "5WEHLSXdcrvo",
    "outputId": "0c261675-8469-4367-f9ab-fdcb489fdefb"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 15)\n",
    "wordcloud = WordCloud(background_color = 'white', width = 1200,  height = 1200, max_words = 121).generate(str(data[0]))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.title('Most Popular Items',fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 583
    },
    "colab_type": "code",
    "id": "gM0kNchXdlZN",
    "outputId": "ccb83a24-9c67-41ea-a452-050650f328b9"
   },
   "outputs": [],
   "source": [
    "# looking at the frequency of most popular items \n",
    "\n",
    "plt.rcParams['figure.figsize'] = (18, 7)\n",
    "color = plt.cm.copper(np.linspace(0, 1, 40))\n",
    "data[0].value_counts().head(40).plot.bar(color = color)\n",
    "plt.title('frequency of most popular items', fontsize = 20)\n",
    "plt.xticks(rotation = 90 )\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "\n",
    "y = data[0].value_counts().head(50).to_frame()\n",
    "y.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# plotting a tree map\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20, 20)\n",
    "color = plt.cm.cool(np.linspace(0, 1, 50))\n",
    "squarify.plot(sizes = y.values, label = y.index, alpha=.8, color = color)\n",
    "plt.title('Tree Map for Popular Items')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "data['food'] = 'Food'\n",
    "food = data.truncate(before = -1, after = 15)\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "food = nx.from_pandas_edgelist(food, source = 'food', target = 0, edge_attr = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20, 20)\n",
    "pos = nx.spring_layout(food)\n",
    "color = plt.cm.Wistia(np.linspace(0, 15, 1))\n",
    "nx.draw_networkx_nodes(food, pos, node_size = 15000, node_color = color)\n",
    "nx.draw_networkx_edges(food, pos, width = 3, alpha = 0.6, edge_color = 'black')\n",
    "nx.draw_networkx_labels(food, pos, font_size = 20, font_family = 'sans-serif')\n",
    "plt.axis('off')\n",
    "plt.grid()\n",
    "plt.title('Top 15 First Choices', fontsize = 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "data['secondchoice'] = 'Second Choice'\n",
    "secondchoice = data.truncate(before = -1, after = 15)\n",
    "secondchoice = nx.from_pandas_edgelist(secondchoice, source = 'food', target = 1, edge_attr = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20, 20)\n",
    "pos = nx.spring_layout(secondchoice)\n",
    "color = plt.cm.Blues(np.linspace(0, 15, 1))\n",
    "nx.draw_networkx_nodes(secondchoice, pos, node_size = 15000, node_color = color)\n",
    "nx.draw_networkx_edges(secondchoice, pos, width = 3, alpha = 0.6, edge_color = 'brown')\n",
    "nx.draw_networkx_labels(secondchoice, pos, font_size = 20, font_family = 'sans-serif')\n",
    "plt.axis('off')\n",
    "plt.grid()\n",
    "plt.title('Top 15 Second Choices', fontsize = 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['thirdchoice'] = 'Third Choice'\n",
    "secondchoice = data.truncate(before = -1, after = 10)\n",
    "secondchoice = nx.from_pandas_edgelist(secondchoice, source = 'food', target = 2, edge_attr = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20, 20)\n",
    "pos = nx.spring_layout(secondchoice)\n",
    "color = plt.cm.Reds(np.linspace(0, 15, 1))\n",
    "nx.draw_networkx_nodes(secondchoice, pos, node_size = 15000, node_color = color)\n",
    "nx.draw_networkx_edges(secondchoice, pos, width = 3, alpha = 0.6, edge_color = 'pink')\n",
    "nx.draw_networkx_labels(secondchoice, pos, font_size = 20, font_family = 'sans-serif')\n",
    "plt.axis('off')\n",
    "plt.grid()\n",
    "plt.title('Top 10 Third Choices', fontsize = 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CbarYbRvBzdw"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making each customers shopping items an identical list\n",
    "trans = []\n",
    "for i in range(0, 7501):\n",
    "    trans.append([str(data.values[i,j]) for j in range(0, 20)])\n",
    "\n",
    "# conveting it into an numpy array\n",
    "trans = np.array(trans)\n",
    "\n",
    "# checking the shape of the array\n",
    "print(trans.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Transaction encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "te = TransactionEncoder()\n",
    "data = te.fit_transform(trans)\n",
    "data = pd.DataFrame(data, columns = te.columns_)\n",
    "\n",
    "# getting the shape of the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# getting correlations for 121 items would be messy \n",
    "# so let's reduce the items from 121 to 50\n",
    "\n",
    "data = data.loc[:, ['mineral water', 'burgers', 'turkey', 'chocolate', 'frozen vegetables', 'spaghetti',\n",
    "                    'shrimp', 'grated cheese', 'eggs', 'cookies', 'french fries', 'herb & pepper', 'ground beef',\n",
    "                    'tomatoes', 'milk', 'escalope', 'fresh tuna', 'red wine', 'ham', 'cake', 'green tea',\n",
    "                    'whole wheat pasta', 'pancakes', 'soup', 'muffins', 'energy bar', 'olive oil', 'champagne', \n",
    "                    'avocado', 'pepper', 'butter', 'parmesan cheese', 'whole wheat rice', 'low fat yogurt', \n",
    "                    'chicken', 'vegetables mix', 'pickles', 'meatballs', 'frozen smoothie', 'yogurt cake']]\n",
    "\n",
    "# checking the shape\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the columns\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the head of the data\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://blog-c7ff.kxcdn.com/blog/wp-content/uploads/2017/03/Apriori-Algorithm.jpg\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does Apriori Algorithm Work ?\n",
    "\n",
    "A key concept in Apriori algorithm is the anti-monotonicity of the support measure. It assumes that\n",
    "\n",
    "* All subsets of a frequent itemset must be frequent\n",
    "* Similarly, for any infrequent itemset, all its supersets must be infrequent too\n",
    "\n",
    "**Step 1**: Create a frequency table of all the items that occur in all the transactions.\n",
    "\n",
    "**Step 2**: We know that only those elements are significant for which the support is greater than or equal to the threshold support.\n",
    "\n",
    "**Step 3**: The next step is to make all the possible pairs of the significant items keeping in mind that the order doesn’t matter, i.e., AB is same as BA.\n",
    "\n",
    "**Step 4**: We will now count the occurrences of each pair in all the transactions.\n",
    "\n",
    "**Step 5**: Again only those itemsets are significant which cross the support threshold\n",
    "\n",
    "**Step 6**: Now let’s say we would like to look for a set of three items that are purchased together. We will use the itemsets found in step 5 and create a set of 3 items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "#Now, let us return the items and itemsets with at least 5% support:\n",
    "apriori(data, min_support = 0.01, use_colnames = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantage of working with pandas DataFrames is that we can use its convenient features to filter the results. For instance, let's assume we are only interested in itemsets of length 2 that have a support of at least 80 percent. First, we create the frequent itemsets via apriori and add a new column that stores the length of each itemset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting and Filtering the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets = apriori(data, min_support = 0.05, use_colnames=True)\n",
    "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting th item sets with length = 2 and support more han 10%\n",
    "\n",
    "frequent_itemsets[ (frequent_itemsets['length'] == 2) &\n",
    "                   (frequent_itemsets['support'] >= 0.01) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting th item sets with length = 2 and support more han 10%\n",
    "\n",
    "frequent_itemsets[ (frequent_itemsets['length'] == 1) &\n",
    "                   (frequent_itemsets['support'] >= 0.01) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets[ frequent_itemsets['itemsets'] == {'eggs', 'mineral water'} ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets[ frequent_itemsets['itemsets'] == {'mineral water'} ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets[ frequent_itemsets['itemsets'] == {'milk'} ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets[ frequent_itemsets['itemsets'] == {'chicken'} ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets[ frequent_itemsets['itemsets'] == {'frozen vegetables'} ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets[ frequent_itemsets['itemsets'] == {'chocolate'} ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Market_Basket.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
